{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1YgW9g7jvunl9JG2q6_vKf-CeXS2ZsqeF",
      "authorship_tag": "ABX9TyM4/2CQMcJpuFjYIVFzzSJC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anaswaraku/Kidney-disease-detection/blob/main/VGG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jj2KULpSMBWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpSWP7elQ2lU"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "from imageio.v2 import imread\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_folders = [\"Cyst\", \"Stone\", \"Tumor\", \"Normal\"]\n",
        "flat_data_arr = []\n",
        "target_arr = []\n",
        "base_dir = '/content/drive/MyDrive/Kidney-disease-detetction/Trial/TrialTrain'\n",
        "output_dir = '/content/drive/MyDrive/Kidney-disease-detetction/Trial/TrialTrain/Preprocessed'"
      ],
      "metadata": {
        "id": "hFoAepPTRS7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to resize images to (224, 224) pixels\n",
        "def resize_images(image_dir):\n",
        "        image = cv2.imread(image_dir, cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.resize(image, (224, 224))\n",
        "        return img"
      ],
      "metadata": {
        "id": "nJhUAzVGdG7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for identical blurring\n",
        "def Gaussian_blur (img):\n",
        "    kernel_size = (5, 5)  # Adjust kernel size as needed\n",
        "    sigma = 0  # Sigma is not directly specified in OpenCV's GaussianBlur\n",
        "    filtered_image = cv2.GaussianBlur(img, kernel_size, sigma)\n",
        "    return filtered_image"
      ],
      "metadata": {
        "id": "1RYKSwuSSYgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clahe(image):\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0,tileGridSize=(8,8))\n",
        "    clahe_image=clahe.apply(image)\n",
        "    return clahe_image"
      ],
      "metadata": {
        "id": "a5KRX_IQaLhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def histogram_equalization(img):\n",
        "  img_yuv = cv2.cvtColor(img,cv2.COLOR_BGR2YUV)\n",
        "  img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n",
        "  equalized_img = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)\n",
        "  return(equalized_img)"
      ],
      "metadata": {
        "id": "X7JpKvy1Sxyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def min_max_scaling(img):\n",
        "  scaler = MinMaxScaler()\n",
        "  img_scaled = scaler.fit_transform(img.flatten().reshape(-1, 1)).reshape(img.shape)\n",
        "  return(img_scaled)"
      ],
      "metadata": {
        "id": "0IbwWjLRTQfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for image augmentation\n",
        "def image_augmentation(img):\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "\n",
        "    # Remove the batch size dimension\n",
        "    aug_img = img[0]\n",
        "    return aug_img\n"
      ],
      "metadata": {
        "id": "9Cc70pFlTc-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for folder in data_folders:\n",
        "    folder_path = os.path.join(base_dir, folder)\n",
        "    print(\"Folder Path:\", folder_path)\n",
        "    output_folder = os.path.join(output_dir, folder)\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(\".jpg\"):\n",
        "            image_path = os.path.join(folder_path, filename)\n",
        "            # Preprocess image\n",
        "            preprocessed_image = resize_images(image_path)\n",
        "            preprocessed_image = Gaussian_blur(preprocessed_image)\n",
        "            preprocessed_image = clahe(preprocessed_image)\n",
        "            preprocessed_image = min_max_scaling(preprocessed_image)\n",
        "            preprocessed_image = image_augmentation(preprocessed_image)\n",
        "\n",
        "            # Save preprocessed image\n",
        "            output_path = os.path.join(output_folder, filename)\n",
        "            cv2.imwrite(output_path, preprocessed_image)\n",
        "print('Preprocess Completed')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1ZOmCy-RU32",
        "outputId": "826b05ce-5780-4cf9-cd71-e2839b8e5902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder Path: /content/drive/MyDrive/Kidney-disease-detetction/Trial/TrialTrain/Cyst\n",
            "Folder Path: /content/drive/MyDrive/Kidney-disease-detetction/Trial/TrialTrain/Stone\n",
            "Folder Path: /content/drive/MyDrive/Kidney-disease-detetction/Trial/TrialTrain/Tumor\n",
            "Folder Path: /content/drive/MyDrive/Kidney-disease-detetction/Trial/TrialTrain/Normal\n",
            "Preprocess Completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VGG-16**"
      ],
      "metadata": {
        "id": "X7fUOcJ-vch1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define paths\n",
        "data_dir = '/content/drive/MyDrive/Kidney-disease-detetction/Trial/TrialTrain/Preprocessed'\n",
        "classes = ['Cyst', 'Normal', 'Tumor', 'Stone']\n",
        "\n",
        "# Create directories for train, test, and validation data\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "test_dir = os.path.join(data_dir, 'test')\n",
        "val_dir = os.path.join(data_dir, 'validation')\n",
        "for directory in [train_dir, test_dir, val_dir]:\n",
        "    for class_name in classes:\n",
        "        os.makedirs(os.path.join(directory, class_name), exist_ok=True)\n",
        "\n",
        "# Split dataset into train, test, and validation sets\n",
        "for class_name in classes:\n",
        "    class_dir = os.path.join(data_dir, class_name)\n",
        "    images = [f for f in os.listdir(class_dir) if f.endswith('.jpg')]\n",
        "    train_images, test_val_images = train_test_split(images, test_size=0.3, random_state=42)\n",
        "    test_images, val_images = train_test_split(test_val_images, test_size=0.5, random_state=42)\n",
        "\n",
        "    # Move images to corresponding directories\n",
        "    for image in train_images:\n",
        "        src = os.path.join(class_dir, image)\n",
        "        dest = os.path.join(train_dir, class_name, image)\n",
        "        shutil.copy(src, dest)\n",
        "    for image in test_images:\n",
        "        src = os.path.join(class_dir, image)\n",
        "        dest = os.path.join(test_dir, class_name, image)\n",
        "        shutil.copy(src, dest)\n",
        "    for image in val_images:\n",
        "        src = os.path.join(class_dir, image)\n",
        "        dest = os.path.join(val_dir, class_name, image)\n",
        "        shutil.copy(src, dest)\n",
        "\n",
        "print(\"Dataset split into train, test, and validation sets.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUtjnFy6vhm1",
        "outputId": "78f74008-ddbd-4466-a7b6-d892ef073256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset split into train, test, and validation sets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "metadata": {
        "id": "xCeWL0Ka0yk7"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Define image dimensions and batch size\n",
        "img_width, img_height = 224, 224\n",
        "batch_size = 32\n",
        "\n",
        "# Define paths to training and validation data\n",
        "train_data_dir = '/content/drive/MyDrive/Preprocessed/train'\n",
        "validation_data_dir = '/content/drive/MyDrive/Preprocessed/validation'"
      ],
      "metadata": {
        "id": "2PA-shVP0y4l"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation and normalization\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_data_dir = '/content/drive/MyDrive/Preprocessed/test'\n",
        "test_generator = train_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        "\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iSlcBMU0y78",
        "outputId": "e54753ec-af1e-4dfa-b090-f61f92d57141"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2099 images belonging to 4 classes.\n",
            "Found 9791 images belonging to 4 classes.\n",
            "Found 2100 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the VGG-16 model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(img_height, img_width, 3)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4, activation='softmax'))  # 5 classes: cyst, normal, tumor, stone, and kidney\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=0.001),\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3nT9DHT0n4C",
        "outputId": "d7563b76-2ced-47eb-8ca4-084487964478"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size,\n",
        "    epochs=20)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('vgg16_kidney_classification.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yr23zSaPXI9n",
        "outputId": "3f8d9c1a-acdc-4de0-cc25-35caa90ebb01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "  3/305 [..............................] - ETA: 6:25:59 - loss: 1.4173 - accuracy: 0.2292"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Load the trained model\n",
        "trained_model = load_model('vgg16_kidney_classification.h5')\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = trained_model.evaluate(test_generator)\n",
        "\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Accuracy:', test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEQJtk7A6cjq",
        "outputId": "7b1adb46-ea50-4f28-e1a2-8fe9b08fa094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 1293s 20s/step - loss: 1.3871 - accuracy: 0.2522\n",
            "Test Loss: 1.3870989084243774\n",
            "Test Accuracy: 0.2522343695163727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test Loss:', test_loss*100)\n",
        "print('Test Accuracy:', test_accuracy*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPeiBgH_8e9v",
        "outputId": "5c149aac-eb22-45a8-8bbe-765c0fdca915"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 138.72514963150024\n",
            "Test Accuracy: 25.0\n"
          ]
        }
      ]
    }
  ]
}